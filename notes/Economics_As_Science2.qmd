---
title: "The Empirical Pivot: From Laws to Stochastic Models"
author: 'Harrison Youn<br><span style="font-size: 0.8em; color: #6c757d;">Economics as Science 2</span>'
date: "2026-01-06"
description: "How did economists transform the positivist ideal into a disciplined empirical craft?"
image: "/assets/images/Economics_As_Science2.png"
categories: [Economic Methodology, Econometrics, History of Economic Thought]
format:
  html:
    toc: true
    toc-depth: 3
    theme: cosmo
    code-fold: true
---

## Beyond Logic: The Birth of Econometric Ambition

If logical positivism offered a formal grammar of science, mid-twentieth century economists tried to write its prose through a disciplined marriage of theory and data. Once the verifiability principle cracked, a practical question remained. If universal laws cannot be verified, what does it mean to justify economic theory empirically?

The answer was not a single philosophical criterion. It was a craft: **econometrics**, a research program aimed at turning economics into a theoretical-quantitative science.

The earliest public stress test of this ambition was the **Keynes–Tinbergen debate**. Keynes pressed the central vulnerability of non-experimental inference. If the economy is not a laboratory, then empirical “tests” depend on whether we can defend everything that stands between a theoretical mechanism and the data used to evaluate it.

This is the problem that haunts every applied paper written with observational data:

**Can a social science discover stable structure in a world where controlled experiments are absent and “other things equal” is rarely true?**

![](/assets/images/Economics_As_Science2.png)

---

## Haavelmo’s Probability Turn: The Modern Foundation

Trygve Haavelmo’s *probability approach* (1944) changed what it meant for an economic model to be empirically meaningful. The shift was not “more mathematics.” It was a redefinition of the object of inquiry.

A model is not a deterministic law written onto the world. A model is a **stochastic data-generating system** that implies a distribution over observables.

A compact template is:

\[
Y = g(X,\theta,U), \qquad U \sim F_U,\qquad \Rightarrow \qquad P_\theta(Y,X).
\]

The scientific content of the model is the family of distributions \(\{P_\theta\}_{\theta\in\Theta}\) it allows. Estimation and testing become logically coherent only when the mapping \(\theta \mapsto P_\theta\) is informative.

### Identification as the logical hinge

Haavelmo’s deeper message is that “more data” cannot rescue a model that is not **identified**. Identification is not a statistical nicety. It is a logical precondition for learning.

::: {.callout-note title="Identification as Non-Observational-Equivalence"}
Let the observable population distribution be \(P\), and let the model imply \(\{P_\theta : \theta \in \Theta\}\).
The parameter \(\theta\) is (point) **identified** if
\[
P_\theta = P_{\theta'} \Rightarrow \theta = \theta'.
\]
If distinct parameters generate the same observable distribution, they are **observationally equivalent**, and no amount of data can logically distinguish them.
:::

This is exactly why econometrics becomes a theory of **restrictions**. Without restrictions, models can be empirically underdetermined even when they are internally elegant.

---

## A Minimal Identification Parable: Supply, Demand, and What Data Cannot Tell You

Consider the textbook market system:

\[
Q^d = \alpha - \beta P + u_d,\qquad \beta > 0,
\]
\[
Q^s = \gamma + \delta P + u_s,\qquad \delta > 0,
\]
\[
Q^d = Q^s = Q.
\]

Solving yields equilibrium price

\[
P = \frac{\alpha-\gamma + (u_d - u_s)}{\beta + \delta}.
\]

If you only observe \((P,Q)\) generated by equilibrium, variation in \(P\) reflects a mixture of demand and supply shocks. A regression of \(Q\) on \(P\) does not isolate \(-\beta\). It loads on an endogenous equilibrium object.

Identification requires a **source of variation** that shifts one equation while leaving the other unchanged. Suppose you have a cost shifter \(Z\) that enters only supply:

\[
Q^s = \gamma + \delta P + \pi Z + u_s,\qquad \pi \neq 0.
\]

Then \(Z\) moves \(P\) through the supply side while holding demand fixed, and an instrumental variables logic becomes available. In the simplest linear-IV form, the demand slope can be pinned down by covariation induced by \(Z\), not by the raw equilibrium correlation between \(Q\) and \(P\).

The methodological point is not the market example. It is the structure:

> empirical content requires a defended mapping from theory to an identifiable implication in the distribution of observables.

---

## Measurement Without Theory vs Theory Without Measurement

Econometrics also inherited an internal tension about what counts as good science.

- The NBER tradition emphasized careful measurement and descriptive regularities.
- The Cowles tradition emphasized structural modeling guided by theory and estimated with statistical methods.

Koopmans’s critique, often summarized as “measurement without theory,” is best read as a warning about scientific structure. Description without a disciplined theoretical map risks becoming a catalogue of correlations that does not cumulate. Yet the counter-warning is equally sharp. Structure without credible measurement risks becoming a symbol-manipulation exercise, insulated from what data can actually support.

Modern empirical economics lives inside this negotiation. It oscillates between two virtues:

- **discipline of measurement**, and
- **discipline of mechanism**.

---

## Friedman’s “As-If” Defense: Not Anti-Realism, but Re-Ranking of Virtues

Milton Friedman’s 1953 essay redirected methodology toward **predictive appraisal**. It is often paraphrased as “assumptions can be false.” That paraphrase is too crude.

A more precise reading is:

- models are not assessed as literal descriptions,
- models are assessed by the performance of their **testable implications**,
- and methodological evaluation should focus on whether those implications survive discriminating empirical challenges.

This framing also clarifies what “as-if” does and does not claim. It is not a metaphysical claim about how agents truly think. It is a methodological claim about what is worth demanding from a scientific model, given the goal of disciplined prediction.

### Untwisting the F-twist

A serious criticism, developed in later philosophy of economics, is that “unrealistic assumptions” are not all the same. Some are:
- **negligibility** assumptions (setting small forces to zero),
- **domain** assumptions (restricting the scope where a model is intended to apply),
- **heuristic** assumptions (temporary scaffolding used to explore).

Confusing these categories makes methodological debates look shallow. Distinguishing them makes the debate scientifically productive.

---

## Internal Validity, External Validity, and the Threat of Curve-Fitting

Econometrics did not abandon the positivist demand for empirical discipline. It changed the form of that discipline.

- **Internal validity** is enforced by identification arguments and research design.
- **External validity** is pressured by predictive performance, stability, and transportability.

The hard boundary question then becomes:

**If every model is false as a description, what prevents empirical economics from collapsing into mere curve-fitting?**

One answer is institutional and procedural: we make tests harder. We separate discovery from evaluation, use out-of-sample prediction, demand robustness, and increasingly lean on designs that approximate experiments.

That answer points directly to the next philosophical move. Not the logic of estimation, but the logic of criticism.

Part 3 turns to Popper.

---

## References

- Boumans, Marcel, and John B. Davis. *Economic Methodology: Understanding Economics as a Science* (2nd ed.). Bloomsbury, 2016
- Haavelmo, Trygve. *The Probability Approach in Econometrics* (1944)
- Keynes, John Maynard. “Professor Tinbergen’s Method” (1939)
- Koopmans, Tjalling C. “Measurement Without Theory” (1947)
- Friedman, Milton. “The Methodology of Positive Economics” (1953)
- Musgrave, Alan. “‘Unreal Assumptions’ in Economic Theory: The F-Twist Untwisted” (1981)
---
