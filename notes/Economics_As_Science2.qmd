---
title: "The Empirical Pivot: From Laws to Stochastic Models"
author: 'Harrison Youn<br><span style="font-size: 0.8em; color: #6c757d;">Economics as Science 2</span>'
date: "2026-01-06"
description: "How did economists transform the positivist ideal into a disciplined empirical craft?"
image: "/assets/images/Economics_As_Science2.png"
categories: [Economic Methodology, Econometrics, Positive Economics, Haavelmo, Friedman]
from: markdown+tex_math_dollars+tex_math_single_backslash
format:
  html:
    toc: true
    toc-depth: 3
    theme: cosmo
    code-fold: true
    html-math-method: mathjax
---

## Beyond Logic: The Birth of Econometric Ambition

Logical positivism promised a sharp demarcation: meaningful knowledge would be either analytic, or empirically checkable in principle. Its collapse did not leave economists empty-handed. It left them with a more demanding, and ultimately more fruitful, problem.

If universal laws cannot be verified, what does it mean to justify an economic mechanism empirically?

The twentieth-century response was not a new philosophical litmus test. It was an institutionalized craft, **econometrics**, a discipline that tried to bind three methodological ideals into a single workflow:

1. **theoretical structure** that supports counterfactual reasoning,
2. **measurement conventions** that connect theoretical terms to observables,
3. **statistical inference** that disciplines belief under uncertainty.

This craft did not arise as a toolbox added to an otherwise complete science. It arose as an attempt to *rebuild* scientific warrant under the constraints of observational data. In a laboratory science, one can often interpret failure as a clean refutation of a mechanism. In economics, failure is frequently ambiguous. It can be a failure of theory, measurement, environment, or inference. Econometrics is, in large part, a systematic attempt to manage that ambiguity rather than deny it.

![](/assets/images/Economics_As_Science2.png)

---

## The Keynes–Tinbergen Controversy: When the Economy Refuses to Be a Laboratory

The earliest public stress test for econometric ambition was the Keynes–Tinbergen controversy. Tinbergen’s project was audacious: estimate quantitative relations among macro variables and use them to arbitrate between competing theories and policy proposals. Keynes’s critique is often remembered for its sharp rhetoric, but the durable point is methodological.

In the natural sciences, a controlled experiment isolates causal pathways by design. In macroeconomics, where “other things equal” is rarely secured by nature, a test of a theory must travel through a chain of auxiliary commitments:

- which variables are included and which are excluded,
- how they are measured and aggregated,
- whether omitted forces are negligible,
- whether institutions and policy rules remain stable,
- whether the estimated relation is robust to feedback and anticipation.

Keynes was pressing a fragile link: statistical fit is not, by itself, scientific warrant. Fit can be achieved through specification search, through mismeasurement, or through unstable correlations. A model earns scientific standing only if it survives not merely a regression, but a defensible interpretive bridge from theoretical mechanism to the observed data.

The question the debate bequeathed to modern applied work remains the right one:

**When evidence contradicts an economic model, what exactly has failed: the mechanism, the measurement, the environment, or the inference?**

A mature econometric methodology does not pretend this question is easy. It makes the difficulty explicit, and then tries to constrain the space of escape routes.

---

## Haavelmo’s Probability Turn: What Makes a Model Empirically Meaningful

Trygve Haavelmo’s *probability approach* (1944) is often described as the importation of “modern statistics” into economics. That description understates the conceptual revolution.

Haavelmo redefined what an economic model is, and therefore what it means to test one. A model is not a deterministic sentence written onto the world. A model is a **stochastic data-generating system**: a disciplined proposal for how observables could have been generated.

A compact template is:

$$
Y = g(X,\theta,U), \qquad U \sim F_U, \qquad \Rightarrow \quad (Y,X)\sim P_\theta.
$$

The scientific content of the model is the family of probability laws $\{P_\theta\}_{\theta\in\Theta}$ it permits. In this view, empirical work is not about “matching a curve.” It is about asking whether the data could plausibly have been generated by the model’s implied distributional structure.

This turns empirical economics into a problem of *logical mapping*:

- what restrictions connect theoretical primitives to observables,
- what observable implications those restrictions generate,
- and what evidence would genuinely count against them.

### Identification as the logical hinge

Haavelmo’s deeper message is that “more data” cannot rescue a model that is not **identified**. Identification is not a statistical nicety. It is a logical precondition for learning from evidence.

::: {.callout-note title="Identification as Non-Observational Equivalence"}
Let the population distribution of observables be $P$, and let the model imply the set $\{P_\theta : \theta\in\Theta\}$.

The parameter $\theta$ is (point) **identified** if

$$
P_\theta = P_{\theta'} \ \Rightarrow\ \theta = \theta'.
$$

If distinct parameters generate the same observable distribution, they are **observationally equivalent**, and no amount of data can logically distinguish them.
:::

This definition is not pedantry. It is a criterion for whether a parameter is even a candidate for scientific knowledge. If the mapping $\theta \mapsto P_\theta$ is not injective, then estimation is not “hard,” it is conceptually ill-posed.

---

## A Minimal Identification Parable: Why Equilibrium Data Do Not Reveal a Demand Curve

Consider the textbook market system:

$$
Q^d = \alpha - \beta P + u_d, \qquad \beta>0,
$$

$$
Q^s = \gamma + \delta P + u_s, \qquad \delta>0,
$$

$$
Q^d = Q^s = Q.
$$

Solving for equilibrium price yields:

$$
P = \frac{\alpha-\gamma + (u_d-u_s)}{\beta+\delta}.
$$

If you only observe equilibrium $(P,Q)$, variation in $P$ reflects a mixture of demand and supply shocks. The naive regression of $Q$ on $P$ does not identify $-\beta$. It loads on an endogenous equilibrium object.

The deeper lesson is not merely “endogeneity.” It is that equilibrium data often collapse multiple structural objects into a single reduced-form correlation. Without a defended source of variation that isolates one margin, the model cannot tell you which parameter you are learning.

Identification arrives only when you can defend a source of variation that shifts one equation while leaving the other unchanged. Suppose you have a cost shifter $Z$ that enters supply but not demand:

$$
Q^s = \gamma + \delta P + \pi Z + u_s, \qquad \pi\neq 0.
$$

Then $Z$ moves $P$ through supply while holding demand fixed. Under an exclusion restriction and an exogeneity claim, the demand slope becomes an identifiable object.

Seen this way, “instrumental variables” is not primarily a trick for bias correction. It is a logical device for restoring distinctness between theoretical parameters that are otherwise observationally entangled.

The methodological point is not the market example. It is the general structure:

> a model becomes empirically meaningful only when it implies an identifiable mapping from theoretical parameters to observable distributions.

---

## Structural Versus Reduced Form: What Econometrics Is Really Choosing Between

Haavelmo’s framework clarifies a distinction that later dominates econometric practice.

- A **structural** model targets parameters with mechanistic interpretation, suitable for counterfactual policy analysis.
- A **reduced-form** relation captures stable predictive regularities, often with fewer assumptions about the underlying mechanism.

Both can be scientifically valuable, but they bear different burdens.

A structural claim demands defended invariance under interventions. A reduced-form claim demands defended stability over the environments where you plan to use it. In modern language, the difference is often framed as a trade-off between interpretability and robustness, or between transportability and mechanism.

Either way, the scientific burden is not eliminated. It is relocated. What changes is *which* assumptions you are asking your reader to accept, and therefore which failure modes you must take seriously.

---

## Measurement Without Theory, and Theory Without Measurement

The next methodological conflict was internal to empirical work itself.

On one side was the NBER tradition: careful measurement, business-cycle dating, and the accumulation of descriptive regularities. On the other side was the Cowles tradition: structural modeling, simultaneous equations, and statistical inference guided by explicit theory.

Koopmans’s charge, often paraphrased as “measurement without theory,” is best read as a claim about scientific cumulation. Without theoretical scaffolding, measurement risks becoming an archive of correlations that does not converge on explanation. Yet the counter-charge is equally serious. Theory without credible measurement risks becoming a closed symbolic exercise, insulated from what data can actually sustain.

Modern empirical economics still lives inside this tension. The discipline oscillates between two virtues:

- **disciplined description** and **disciplined mechanism**.

The best work treats the tension as productive. It uses description to discover anomalies and regularities worth explaining, then uses mechanism to make sense of them, and then returns to measurement to test whether the mechanism survives the world’s resistance.

---

## Friedman’s “As If” Defence: A Re-Ranking of Scientific Virtues

Milton Friedman’s methodological essay shifted attention from the realism of assumptions to the performance of a model’s **testable implications**. It is often caricatured as “assumptions can be false.” The stronger reading is methodological:

- models are not evaluated as literal descriptions of the world,
- models are evaluated by whether their implications survive discriminating tests,
- predictive success is a form of methodological selection under criticism.

This framing also clarifies what “as if” does and does not claim. It is not a metaphysical thesis about cognition. It is a claim about what should count as scientific appraisal when the goal is disciplined prediction.

The most constructive way to read Friedman is to treat him as proposing a competitive model of scientific appraisal: theories earn their place not by being psychologically realistic, but by surviving comparison against rivals on the dimensions the discipline cares about, especially predictive discrimination.

### Untwisting the F-twist

A serious improvement, developed in later philosophy of economics, is to recognize that “unrealistic assumptions” are not all of one kind. Some assumptions are:

- **negligibility** assumptions, setting small forces to zero,
- **domain** assumptions, restricting the scope where a model is intended to apply,
- **heuristic** assumptions, temporary scaffolding that supports exploration.

Conflating these makes debates look superficial. Distinguishing them makes methodological criticism sharp. It also explains why economists can rationally keep certain stylizations while rejecting others. The crucial question becomes: does the assumption merely simplify, or does it do substantive work that is empirically consequential?

---

## The Boundary Problem Returns: What Prevents Curve Fitting?

If a model is a stochastic generator, and if assumptions are not literal descriptions, a skeptical reader will ask: why is econometrics not merely curve fitting?

The best answer is not a slogan. It is a practice: increase the difficulty of survival.

- defend identification, not just statistical significance,
- separate exploration from evaluation when possible,
- use out-of-sample validation when prediction is the goal,
- run placebo tests and falsification checks when causal interpretation is the goal,
- demand robustness that targets plausible failure modes rather than cosmetic variations.

This is a methodological pivot away from verification as certainty and toward criticism as discipline.

To make that pivot explicit, we need the next philosophical move. We need a logic of risk.

That is where Popper enters.

---

## References

- Trygve Haavelmo (1944), *The Probability Approach in Econometrics* (Cowles Foundation Paper No. 4).
- J. M. Keynes (1939), “Professor Tinbergen’s Method,” *The Economic Journal*.
- Tjalling C. Koopmans (1947), “Measurement Without Theory,” *The Review of Economics and Statistics*.
- Milton Friedman (1953), “The Methodology of Positive Economics,” in *Essays in Positive Economics*.
- Alan Musgrave (1981), “‘Unreal Assumptions’ in Economic Theory: The F-Twist Untwisted,” *Kyklos*.
---
